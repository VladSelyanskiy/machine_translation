Да, вы правы. Таким образом, поскольку локально взвешенная регрессия является непараметрическим алгоритмом, каждый раз, когда вы делаете прогноз, вам нужно заново сопоставлять тета-значение со всей вашей тренировочной выборкой. Итак, вы на самом деле правы. Если у вас очень большая обучающая выборка, то использовать этот алгоритм довольно дорого. Потому что каждый раз, когда вы хотите сделать прогноз, вам нужно снова сопоставлять прямую линию с огромным набором данных. Оказывается, существуют алгоритмы, которые... оказывается, есть способы сделать это намного эффективнее и для больших наборов данных. Поэтому не хочу говорить об этом. Если вам интересно, ознакомьтесь с работой Эндрю Мура о KD-деревьях. Он, в некотором роде, придумал, как гораздо эффективнее использовать эти модели.